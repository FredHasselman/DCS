[
["mathematics-of-change-i.html", "A Mathematics of change I", " A Mathematics of change I Solutions to assignments in section ??. Linear and logistic growth Deterministic Chaos "],
["linear-and-logistic-growth.html", "A.1 Linear and logistic growth", " A.1 Linear and logistic growth Solutions in a spreadsheet The solutions to iterating the Linear Map and theLogistic Map in a spreadsheet can be found in this GoogleSheet. Solutions in R | jump to question | Coding the difference equations in Matlab and R is always easier than using a spreadsheet. One obvious way to do it is to use a counter variable representing the iterations of time in a for ... next loop. The iterations should run over a vector (which is the same concept as a row or a column in a spreadsheet: An indexed array of numbers or characters). The first entry should be the starting value, so the vector index \\(1\\) represents \\(Y_0\\). The loop can be implemented a number of ways, for example as a function which can be called from a script or the command / console window. In R working with functions is easy, and very much recommended, because it will speed up calculations considerably, and it will reduce the amount of code you need to write. You need to gain some experience with coding in R before you’ll get it right. In order to get it lean and clean (and possibly even mean as well) you’ll need a lot of experience with coding in R,therefore, we will (eventually) provide you the functions you’ll need to complete the assignments. All you have to do is figure out how to use, or modify them to suit your specific needs. To model the autocatalytic growth equations we provide a function growth.ac(), which is able to simulate all of the processes discussed in the lectures. Using just a few lines of code, each of the 4 difference equations used in the assignments can be simulated. Basically the code block below contains the solutions to the Linear Map, the stylized Logisitc Map and the Van Geert model for cognitive growth. growth.ac &lt;- function(Y0 = 0.01, r = 1, k = 1, N = 100, type = c(&quot;driving&quot;, &quot;damping&quot;, &quot;logistic&quot;, &quot;vanGeert&quot;)[1]){ # Create a vector Y of length N, which has value Y0 at Y[1] if(N&gt;1){ Y &lt;- as.numeric(c(Y0, rep(NA,N-2))) # Conditional on the value of type ... switch(type, # Iterate N steps of the difference function with values passed for Y0, k and r. driving = sapply(seq_along(Y), function(t) Y[[t+1]] &lt;&lt;- r * Y[t] ), damping = k + sapply(seq_along(Y), function(t) Y[[t+1]] &lt;&lt;- - r * Y[t]^2 / k), logistic = sapply(seq_along(Y), function(t) Y[[t+1]] &lt;&lt;- r * Y[t] * ((k - Y[t]) / k)), vanGeert = sapply(seq_along(Y), function(t) Y[[t+1]] &lt;&lt;- Y[t] * (1 + r - r * Y[t] / k)) )} return(ts(Y)) } # Call the function with default settings and r = 1.1 Y &lt;- growth.ac(r = 1.1) Some notes about this function: To select which growth process to simulate, the argument type is defined which takes the values driving (default), damping, logistic and vanGeert. The statement switch(type, ...) will iterate an equation based on the value of type. A time series object is returned due to the function ts(). This is a convenient way to represent time series data, it can also store the sample rate of the signal and start and end times. Most of the basic functions, like plot() and summary() will recognise a time series object when it is passed as an argument and use settings appropriate for time series data. The sapply() function iterates \\(t\\) from \\(1\\) to the number of elements in \\(Y\\) (seq_along(Y)) and then applies the function. The double headed arrow &lt;&lt;- is necessary because we want to update vector \\(Y\\), which is defined outside the sapply() environment. The time series object The time series object is expected to have a time-dimension on the x-axis. This is very convenient, because R will generate the time axis for you by looking at the time series properties attribute of the object. Even though we are not working with measurement ourcomes, consider a value at a time-index in a time series object a sample: Start - The value of time at the first sample in the series (e.g., \\(0\\), or \\(1905\\)) End - The value of time at the last sample in the series (e.g., \\(100\\), or \\(2005\\)) Frequency - The amount of time that passed between two samples, or, the sample rate (e.g., \\(0.5\\), or \\(10\\)) Examples of using the time series object. # Get sample rate info tsp(Y) [1] 1 100 1 # Extract the time vector time(Y) Time Series: Start = 1 End = 100 Frequency = 1 [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [18] 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 [35] 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 [52] 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 [69] 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 [86] 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 For now, these values are in principle all arbitrary units (a.u.). These settings only make sense if they represent the parameters of an actual measurement procedure. It is easy to adjust the time vector, by assigning new values using tsp() (values have to be possible given the timeseries length). For example, suppose the sampling frequency was \\(0.1\\) instead of \\(1\\) and the Start time was \\(10\\) and End time was \\(1000\\). # Assign new values tsp(Y) &lt;- c(10, 1000, .1) # Time axis is automatically adjusted time(Y) Time Series: Start = 10 End = 1000 Frequency = 0.1 [1] 10 20 30 40 50 60 70 80 90 100 110 120 130 140 [15] 150 160 170 180 190 200 210 220 230 240 250 260 270 280 [29] 290 300 310 320 330 340 350 360 370 380 390 400 410 420 [43] 430 440 450 460 470 480 490 500 510 520 530 540 550 560 [57] 570 580 590 600 610 620 630 640 650 660 670 680 690 700 [71] 710 720 730 740 750 760 770 780 790 800 810 820 830 840 [85] 850 860 870 880 890 900 910 920 930 940 950 960 970 980 [99] 990 1000 Plotting a ts object as a time series Depending on which packages you use, there will be different settings applied to time series objects created by ts(). Below are some examples of differences between plotting routines. require(lattice) # Needed for plotting Loading required package: lattice require(latticeExtra) # Needed for plotting Loading required package: latticeExtra Loading required package: RColorBrewer # stats::plot.ts plot(growth.ac(r = -.9), lwd = 2, main = &quot;stats::plot.ts&quot;) # lattice::xyplot.ts xyplot(growth.ac(r = -.9), lwd = 2, main = &quot;lattice::xyplot.ts&quot;) Plotting multiple time series in one figure Plot multiple timeseries in frames with plot.ts() in package::stats. This function takes a matrix as input, here we use cbind( ... ). # stats::plot.ts plot(cbind(growth.ac(r = 0.9), growth.ac(r = 1.0), growth.ac(r = -0.8) ), yax.flip = TRUE, ann = FALSE, col = &quot;blue&quot;, frame.plot = TRUE) title(main = expression(paste(&quot;Unrestricted Growth: &quot;,Y[t+1]==r*Y[t])), ylab = &quot;| r = -0.8 | r = 1 | r = 0.9 |&quot;, xlab = &quot;time (a.u.)&quot;) Plot multiple timeseries in one graph with ts.plot() in package::graphics. This function can handle multiple ts objects as arguments. # graphics::ts.plot ts.plot(growth.ac(r = 0.9), growth.ac(r = 1), growth.ac(r = -.8), gpars = list(xlab = &quot;time (a.u.)&quot;, ylab = expression(Y(t)), main = expression(paste(&quot;Unrestricted Growth: &quot;,Y[t+1]==r*Y[t])), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;) ) ) legend(70, -0.015, c(&quot;r = 0.9&quot;,&quot;r = 1.0&quot;, &quot;r = -0.8&quot;), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;), merge = TRUE) Use xyplot() in package::lattice to create a plot with panels. The easiest way to do this is to create a dataset in so-called “long” format. This means the variable to plot is in 1 column and other variables indicate different levels, or conditions under which the variable was observed or simulated. Function ldply() is used to generate \\(Y\\) for three different settings of \\(r\\). The values of \\(r\\) are passed as a list and after a function is applied the result is returned as a dataframe. require(plyr) # Needed for function ldply() Loading required package: plyr # Create a long format dataframe for various values for `r` data &lt;- ldply(c(0.9,1,-0.8), function(r) cbind.data.frame(Y = as.numeric(growth.ac(r = r)), time = as.numeric(time(growth.ac(r = r))), r = paste0(&quot;r = &quot;, r))) # Plot using the formula interface xyplot(Y ~ time | r, data = data, type = &quot;l&quot;, main = expression(paste(&quot;Unrestricted Growth: &quot;,Y[t+1]==r*Y[t]))) One can also have different panels represent different growth functions. # Create a long format dataframe for combinations of `type` and `r` param &lt;- list(driving = 1.1, damping = 0.9, logistic = 2.9, vanGeert = 1.9) # Use the `names()` function to pass the `type` string as an argument. data &lt;- ldply(seq_along(param), function(p){ cbind.data.frame(Y = as.numeric(growth.ac(r = param[[p]], type = names(param[p]))), time = as.numeric(time(growth.ac(r = param[[p]], type = names(param[p])))), type = paste0(names(param[p]), &quot; | r = &quot;, param[p])) }) # Plot using the formula interface xyplot(Y ~ time | factor(type), data = data, type = &quot;l&quot;, scales = c(relation = &quot;free&quot;), main = &quot;Four Autocatalytic Growth Models&quot;) The return plot To create a return plot the values of \\(Y\\) have to be shifted by a certain lag. The functions lead() and lag() in package::dplyr are excellent for this purpose (note that dplyr::lag() behaves different from stats::lag()). # Function lag() and lead() require(dplyr) Loading required package: dplyr Attaching package: &#39;dplyr&#39; The following objects are masked from &#39;package:plyr&#39;: arrange, count, desc, failwith, id, mutate, rename, summarise, summarize The following objects are masked from &#39;package:stats&#39;: filter, lag The following objects are masked from &#39;package:base&#39;: intersect, setdiff, setequal, union # Get exponential growth Y1 &lt;- growth.ac(Y0 = .9, r = .9, N = 1000, type = &quot;driving&quot;) # Get logistic growth in the chaotic regime Y2 &lt;- growth.ac(r = 4, N = 1000, type = &quot;logistic&quot;) # Use the `lag` function from package `dplyr` op &lt;- par(mfrow = c(1,2), pty = &quot;s&quot;) plot(lag(Y1), Y1, xy.labels = FALSE, pch = &quot;.&quot;, xlim = c(0,1), ylim = c(0,1), xlab = &quot;Y(t)&quot;, ylab = &quot;Y(t+1)&quot;, main = expression(paste(Y[t+1]==r*Y[t]))) plot(lag(Y2), Y2, xy.labels = FALSE, pch = &quot;.&quot;, xlim = c(0,1), ylim = c(0,1), xlab = &quot;Y(t)&quot;, ylab = &quot;Y(t+1)&quot;, main = expression(paste(Y[t+1]==r*Y[t]*(1-Y[t])))) par(op) Use l_ply() from package::plyr to create return plots with different lags. The l_ before ply means the function will take a list as input to a function, but it will not expect any data to be returned, for example in the case of a function that is used to plot something. # Explore different lags op &lt;- par(mfrow = c(1,2), pty = &quot;s&quot;) l_ply(1:4, function(l) plot(lag(Y2, n = l), Y2, xy.labels = FALSE, pch = &quot;.&quot;, xlim = c(0,1), ylim = c(0,1), xlab = &quot;Y(t)&quot;, ylab = paste0(&quot;Y(t+&quot;,l,&quot;)&quot;), cex = .8)) par(op) Solutions in Matlab. For Matlab we provide an example of a simple for ... next loop, which should be easy to translate to R if you want to. Linear Map %%%%%%%%%%%%%% COMPUTING TRAJECTORIES OF THE LOGISTIC MAP %%%%% %% Set these parameters to manipulate the logistic map r = 1,1; % Control parameter value Y0 = 0.01; % Initial condition N = 100; % Number of iterations %% Y = [Y0; NaN(length(1:(N-1)),1)]; % This creates a vector Y of length N % iterate values for t = 1:(N-1) Y(t+1) = r*Y(t); end %% Graphs subplot(2,1,1) % Create a graph the time series figure(1); set(gcf,&#39;Color&#39;,&#39;white&#39;); plot(Y,&#39;k&#39;); xlabel(&#39;Time (discrete)&#39;) ylabel(&#39;Time Evolution of Y&#39;) title([{&#39;Linear Map&#39;},{[&#39;Y_0 = &#39; num2str(Y0) &#39;, r = &#39; num2str(r)]}]) subplot(2,1,2) % Create a graph the return plot set(gcf,&#39;Color&#39;,&#39;white&#39;); plot(Y(1:length(Y)-1),Y(2:length(Y)),&#39;.k&#39;); xlabel(&#39;Y(t)&#39;) ylabel(&#39;Y(t+1)&#39;) title([{&#39;Return Plot&#39;},{[&#39;Y_0 = &#39; num2str(Y0) &#39;, r = &#39; num2str(r)]}]) axis square Logistic Map %%%%%%%%%%%%%% COMPUTING TRAJECTORIES OF THE LOGISTIC MAP %%%%% %% Set these parameters to manipulate the logistic map r = 4; % Control parameter value Y0 = 0.08; % Initial condition N = 100; % Number of iterations %% Y = [Y0; NaN(length(1:(N-1)),1)]; % This creates a vector Y of length N % iterate values for t = 1:(N-1) Y(t+1) = r*Y(t)*(1-Y(t)); end %% Graphs subplot(2,1,1) % Create a graph the time series figure(1); set(gcf,&#39;Color&#39;,&#39;white&#39;); plot(Y,&#39;k&#39;); xlabel(&#39;Time (discrete)&#39;) ylabel(&#39;Time Evolution of Y&#39;) title([{&#39;Logisitc Map&#39;},{[&#39;Y_0 = &#39; num2str(Y0) &#39;, r = &#39; num2str(r)]}]) subplot(2,1,2) % Create a graph the return plot set(gcf,&#39;Color&#39;,&#39;white&#39;); plot(Y(1:length(Y)-1),Y(2:length(Y)),&#39;.k&#39;); xlabel(&#39;Y(t)&#39;) ylabel(&#39;Y(t+1)&#39;) title([{&#39;Return Plot&#39;},{[&#39;Y_0 = &#39; num2str(Y0) &#39;, r = &#39; num2str(r)]}]) axis square Solution Logistic Map - Matlab -->"],
["mathematics-of-change-ii.html", "B Mathematics of Change II", " B Mathematics of Change II Solutions to assignments in section ?? Time-varying parameters Predator-prey dynamics "],
["time-varying-parameters.html", "B.1 Time-varying parameters", " B.1 Time-varying parameters Solutions in a spreadsheet Van Geert, including jumps and stages. B.1.1 Solutions in R The growth model by Van Geert (1991) Different values for r: library(plyr) # Parameters rs &lt;- c(1.2, 2.2, 2.5, 2.7, 2.9, 3) # Plot op &lt;- par(mfrow=c(1,2)) l_ply(rs,function(r){plot(growth.ac(r = r, Y0 = 0.01, type = &quot;vanGeert&quot;), ylim = c(0,1.4), ylab = &quot;L(t)&quot;, main = paste(&quot;r =&quot;,r))}) par(op) Different values for \\(k\\) reveal that the dispersion of values (variance) increases if the carrying capacity increases. This occurs because we are dealing with nonlinear changes to the values of \\(Y\\) and if larger values of \\(Y\\) are allowed by a hihger \\(k\\), these values will be amplified once they occur. # Parameters ks &lt;- c(0.5, 0.75, 1, 1.5) # Plot op &lt;- par(mfrow=c(1,2)) l_ply(ks,function(k){plot(growth.ac(r = 2.9, k = k, Y0 = 0.01, type = &quot;vanGeert&quot;), ylim = c(0, 2), ylab = &quot;L(t)&quot;, main = paste(&quot;k =&quot;,k))}) par(op) Stages and Jumps growth.ac.cond &lt;- function(Y0 = 0.01, r = 0.1, k = 2, cond = cbind.data.frame(Y = 0.2, par = &quot;r&quot;, val = 2), N = 100){ # Create a vector Y of length N, which has value Y0 at Y[1] Y &lt;- c(Y0, rep(NA, N-1)) # Iterate N steps of the difference equation with values passed for Y0, k and r. cnt &lt;- 1 for(t in seq_along(Y)){ # Check if the current value of Y is greater than the threshold for the current conditional rule in cond if(Y[t] &gt; cond$Y[cnt]){ # If the threshold is surpassed, change the parameter settings by evaluating: cond$par = cond$val eval(parse(text = paste(cond$par[cnt], &quot;=&quot;, cond$val[cnt]))) # Update the counter if there is another conditional rule in cond if(cnt &lt; nrow(cond)){cnt &lt;- cnt + 1} } # Van Geert growth model Y[[t+1]] &lt;- Y[t] * (1 + r - r * Y[t] / k) } return(ts(Y)) } # Plot with the default settings (same as first step in the assignment) xyplot(growth.ac.cond()) The ‘trick’ used here is to define the function such that it can take a set of conditional rules and apply them sequentially during the iterations. The conditiona rule is passed as a data.frame, but one could also use a list object. (cond &lt;- cbind.data.frame(Y = c(0.2, 0.6), par = c(&quot;r&quot;, &quot;r&quot;), val = c(0.5, 0.1))) Y par val 1 0.2 r 0.5 2 0.6 r 0.1 xyplot(growth.ac.cond(cond=cond)) Or, combine a change of r and a change of k (cond &lt;- cbind.data.frame(Y = c(0.2, 1.99), par = c(&quot;r&quot;, &quot;k&quot;), val = c(0.5, 3))) Y par val 1 0.20 r 0.5 2 1.99 k 3.0 xyplot(growth.ac.cond(cond=cond)) # A fantasy growth process (cond &lt;- cbind.data.frame(Y = c(0.1, 1.99, 1.999, 2.5, 2.9), par = c(&quot;r&quot;, &quot;k&quot;, &quot;r&quot;, &quot;r&quot;,&quot;k&quot;), val = c(0.3, 3, 0.9, 0.1, 1.3))) Y par val 1 0.100 r 0.3 2 1.990 k 3.0 3 1.999 r 0.9 4 2.500 r 0.1 5 2.900 k 1.3 xyplot(growth.ac.cond(cond=cond)) Connected Growers Somewhat more realstic would be to model a change of r as dependent on the values of another process. The proper ‘dynamical’ way to do this would be to define a coupled system of difference or differential equations in which the interaction dynamics regulate growth. An example is the predator-prey system discussed in the next assignment. Using the ‘conditional’ rules on a number of seperate processes will ‘work’ as a model, but it isn’t exactly what is meant by interaction dynamics, or multiplicative interactions. Basically, these processes will be independent and non-interacting. The conditional rules that change the parameters are ‘given’. # Generate 3 timeseries Y1 &lt;- growth.ac(k = 2, r =.2, type = &quot;vanGeert&quot;) # Y2 and Y3 start at r = 0.001 Y3 &lt;- Y2 &lt;- growth.ac(k = 2, r = 0.001, type = &quot;vanGeert&quot;) # Y2 and Y3 start when k is approached c1 &lt;- 1.6 c2 &lt;- 2.2 Y2[Y1 &gt; c1] &lt;- growth.ac(r = .3, k = 3, type = &quot;vanGeert&quot;, N = sum(Y1 &gt; c1)) Y3[Y2 &gt; c2] &lt;- growth.ac(r = .5, k = 4, type = &quot;vanGeert&quot;, N = sum(Y2 &gt; c2)) # Make a nice plot ts.plot(Y1, Y2, Y3, gpars = list(xlab = &quot;time (a.u.)&quot;, ylab = expression(Y(t)), main = expression(paste(&quot;&#39;Connected&#39; Growers &quot;,Y[t+1]==Y[t]*(1 + r - r*Y[t]))), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;) ) ) legend(1, 3.8, c(&quot;Y1(0): r = .2&quot;, paste0(&quot;Y2(&quot;,which(Y1 &gt; c1)[1],&quot;): r = .3&quot;), paste0(&quot;Y3(&quot;,which(Y2 &gt; c2)[1],&quot;): r = .5&quot;)), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;), merge = TRUE) "],
["ppdsol.html", "B.2 Predator-prey dynamics", " B.2 Predator-prey dynamics | jump to question | Iterating 2D Maps and Flows In order to ‘solve’ a differential equation for time using a method of numerical integration, one could code it like in the spreadsheet assignment. For R and Matlab there are so-called solvers available, functions that will do the integration for you. Look at the Examples in package deSolve. Solutions in a spreadsheet Predator-Prey Dynamics B.2.1 Solutions in R Euler’s method and more… The result of applying a method of numerical integration is called a numerical solution of the differential equation. The analytical solution is the equation which will give you a value of \\(Y\\) for any point in time, given an initial value \\(Y_0\\). Systems which have an analytical solution can be used to test the accuracy of numerical solutions. Remember that the analytical solution for the logistic equation is: \\[\\begin{equation} \\frac{K}{1 + \\left(\\frac{K}{Y_0 - 1}\\right) * e^{-r*t} } \\tag{B.1} \\end{equation}\\] We have the function growth.ac() and could easily adapt all the functions to use Euler’s method. Below is a comparison of the analytic solution with Euler’s method. # Parameter settings d &lt;- 1 N &lt;- 100 r &lt;- .1 k &lt;- 1 Y0 &lt;- 0.01 Y &lt;- as.numeric(c(Y0, rep(NA,N-1))) # Numerical integration of the logistic differential equation Y.euler1 &lt;- ts( sapply(seq_along(Y), function(t) Y[[t+1]] &lt;&lt;- (r * Y[t] * (k - Y[t])) * d + Y[t] )) Y.euler2 &lt;- ts( sapply(seq_along(Y), function(t) Y[[t+1]] &lt;&lt;- (r * Y[t] * (k - Y[t])) * (d+.1) + Y[t] )) ## analytical solution Y.analytic &lt;- ts( k / (1 + (k / Y0 - 1) * exp(-r*(time(Y.euler1)))) ) ts.plot(Y.analytic, Y.euler1, Y.euler2, gpars = list(xlab = &quot;time (a.u.)&quot;, ylab = expression(Y(t)), main = expression(paste(&quot;Analytic vs. Numerical:&quot;,Y[t+1]==Y[t]*(1 + r - r*Y[t]))), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;) ) ) legend(50, 0.4, c(&quot;Analytic&quot;, &quot;Euler: delta = 1.0&quot;, &quot;Euler: delta = 1.1&quot;), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;), merge = TRUE) Numerical integration The Euler setup: \\[\\begin{align} R_{t+1} &amp;= f_R(R_t,Ft) * \\Delta + R_t \\\\ F_{t+1} &amp;= f_F(R_t,F_t) * \\Delta + F_t \\end{align}\\] With the equations: \\[\\begin{align} R_{t+1} &amp;= (a-b*F_t)*R_t * \\Delta + R_t \\\\ \\\\ F_{t+1} &amp;= (c*R_t-d)*F_t * \\Delta + F_t \\end{align}\\] # Parameters N &lt;- 1000 a &lt;- d &lt;- 1 b &lt;- c &lt;- 2 R0 &lt;- F0 &lt;- 0.1 R &lt;- as.numeric(c(R0, rep(NA,N-1))) F &lt;- as.numeric(c(F0, rep(NA,N-1))) # Time constant delta &lt;- 0.01 # Numerical integration of the logistic differential equation l_ply(seq_along(R), function(t){ R[[t+1]] &lt;&lt;- (a - b * F[t]) * R[t] * delta + R[t] F[[t+1]] &lt;&lt;- (c * R[t] - d) * F[t] * delta + F[t] }) # Note different behaviour when ts() is applied xyplot(cbind(ts(R),ts(F))) xyplot(R ~ F, pch = 16) -->"],
["btasol.html", "C Basic Timeseries Analysis ", " C Basic Timeseries Analysis "],
["nonlinear-growth-curves-in-spss.html", "C.1 Nonlinear Growth curves in SPSS", " C.1 Nonlinear Growth curves in SPSS | Jump to question | The solutions are provided as an SPSS syntax file file. Or copy the block below: GRAPH /LINE(SIMPLE)=VALUE(Yt) BY Time. * NonLinear Regression. MODEL PROGRAM Yzero=0.01 r=0.01 K=0.01. COMPUTE PRED_=K*Yzero/(Yzero + (K-Yzero) * EXP(-1*(r * K * Time))). NLR Yt /PRED PRED_ /SAVE PRED /CRITERIA SSCONVERGENCE 1E-8 PCON 1E-8. GRAPH /LINE(MULTIPLE)=VALUE(Yt PRED_) BY Time. COMPUTE T1=Yt * Time. COMPUTE T2=Yt * (Time ** 2). COMPUTE T3=Yt * (Time ** 3). COMPUTE T4=Yt * (Time ** 4). EXECUTE. REGRESSION /MISSING LISTWISE /STATISTICS COEFF OUTS R ANOVA /CRITERIA=PIN(.05) POUT(.10) /NOORIGIN /DEPENDENT Yt /METHOD=ENTER T1 T2 T3 T4 /SAVE PRED. GRAPH /LINE(MULTIPLE)=VALUE(Yt PRED_ PRE_1) BY Time. The point here is that the polynomial regression appoach is “just” curve fitting … adding components until a nice fit is found … but what does component \\(Y_t^4\\) represent? A quartic subprocess? Fitting the solution of the the logistic function will give us parameters we can interpret unambiguoulsy: Carrying capacity, growth rate, starting value. "],
["pacfsol.html", "C.2 Correlation functions and AR-MA models", " C.2 Correlation functions and AR-MA models | Jump to question | The solutions are provided as an SPSS syntax file file. Or copy the block below: DESCRIPTIVES VARIABLES=TS_1 TS_2 TS_3 /STATISTICS=MEAN STDDEV MIN MAX . *Sequence Charts . TSPLOT VARIABLES= TS_1 /NOLOG /FORMAT NOFILL REFERENCE. TSPLOT VARIABLES= TS_2 /NOLOG /FORMAT NOFILL REFERENCE. TSPLOT VARIABLES= TS_3 /NOLOG /FORMAT NOFILL REFERENCE. *ACF and PCF. ACF VARIABLES= TS_1 TS_2 TS_3 /NOLOG /MXAUTO 30 /SERROR=IND /PACF. * ARIMA with p=5 and q=1. TSET PRINT=DEFAULT CIN=95 NEWVAR=ALL . PREDICT THRU END. ARIMA TS_2 /MODEL=( 5 0 1)CONSTANT /MXITER= 10 /PAREPS= .001 /SSQPCT= .001 /FORECAST= EXACT . * ARIMA with p=2 and q=1. TSET PRINT=DEFAULT CIN=95 NEWVAR=ALL . PREDICT THRU END. ARIMA TS_2 /MODEL=( 2 0 1)CONSTANT /MXITER= 10 /PAREPS= .001 /SSQPCT= .001 /FORECAST= EXACT . *Plot Fit. GRAPH /LINE(MULTIPLE)=MEAN(TS_2) MEAN(FIT_2) MEAN(LCL_2) MEAN(UCL_2) BY TIME /MISSING=LISTWISE . *Return plots. COMPUTE TS_1_lag1 = LAG(TS_1) . COMPUTE TS_2_lag1 = LAG(TS_2) . COMPUTE TS_3_lag1 = LAG(TS_3) . EXECUTE . IGRAPH /VIEWNAME=&#39;Scatterplot&#39; /X1 = VAR(TS_1_lag1) TYPE = SCALE /Y = VAR(TS_1) TYPE = SCALE /COORDINATE = VERTICAL /X1LENGTH=3.0 /YLENGTH=3.0 /X2LENGTH=3.0 /CHARTLOOK=&#39;NONE&#39; /SCATTER COINCIDENT = NONE. EXE. IGRAPH /VIEWNAME=&#39;Scatterplot&#39; /X1 = VAR(TS_2_lag1) TYPE = SCALE /Y = VAR(TS_2) TYPE = SCALE /COORDINATE = VERTICAL /X1LENGTH=3.0 /YLENGTH=3.0 /X2LENGTH=3.0 /CHARTLOOK=&#39;NONE&#39; /SCATTER COINCIDENT = NONE. EXE. IGRAPH /VIEWNAME=&#39;Scatterplot&#39; /X1 = VAR(TS_3_lag1) TYPE = SCALE /Y = VAR(TS_3) TYPE = SCALE /COORDINATE = VERTICAL /X1LENGTH=3.0 /YLENGTH=3.0 /X2LENGTH=3.0 /CHARTLOOK=&#39;NONE&#39; /SCATTER COINCIDENT = NONE. EXE. Were you surprised finding out Timeseries 3 is the logisitc map in the chaotic regime? It ruly ‘looks’ random (according to PACF). "],
["using-r-to-fit-the-solutions.html", "C.3 Using R to fit the solutions", " C.3 Using R to fit the solutions There are several packages that can perform nonlinear regression analysis, the function most resembling the approach used by SPSS is nls in the default stats package. The easiest way to do this is to first define your function (i.e., the solution) and then fit it using starting values for the parameters. library(rio) df &lt;- import(&quot;https://raw.githubusercontent.com/FredHasselman/DCS/master/assignmentData/BasicTSA_nonlinreg/GrowthRegression.sav&quot;, setclass = &quot;tbl_df&quot;) # Logistic growth # Same as SPSS syntax: PRED_=K*Yzero/(Yzero + (K-Yzero) * EXP(-1*(r * K * Time))). log.eq &lt;- function(Yzero, r, K, Time) { K*Yzero/(Yzero + (K-Yzero) * exp(-1*(r * K * Time))) } There is one drawback and you can read about in the help pages: Warning Do not use nls on artificial “zero-residual” data. This means, “do not use it on data generated by a deterministic model which has no residual error”, which is exactly what the timeseries in this assignment is, it is the output of the quadratic map in the chaotic regime. So, this will give an error: # Fit this function ... gives an error # The list after &#39;start&#39; provides the initial values m.log &lt;- nls(Yt ~ log.eq(Yzero, r, K, Time), data = df, start = list(Yzero=.01, r=.01, K=1), trace = T) It is possible to fit these ideal data using package minpack.lm, which contains function nlsM. library(minpack.lm) m.log &lt;- nlsLM(Yt ~ log.eq(Yzero, r, K, Time), data = df, start = list(Yzero = .01, r=.01, K=0.1)) summary(m.log) Formula: Yt ~ log.eq(Yzero, r, K, Time) Parameters: Estimate Std. Error t value Pr(&gt;|t|) Yzero 7.055e-03 8.983e-05 78.53 &lt;2e-16 *** r 1.491e-01 4.170e-04 357.59 &lt;2e-16 *** K 1.002e+00 4.376e-04 2289.42 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.002865 on 97 degrees of freedom Number of iterations to convergence: 13 Achieved convergence tolerance: 1.49e-08 In order to look at the model prediction, we use predict() which is defined for almost all modelfitting functions in R Ypred &lt;- predict(m.log) plot(ts(df$Yt), col=&quot;gray40&quot;, lwd=5, ylab = (&quot;Yt | Ypred&quot;)) lines(Ypred, col=&quot;gray80&quot;, lwd=2, lty=2) Then we do a polynomial regression using lm: # Mimic the SPSS syntax attach(df) df$T1 &lt;- Yt * Time df$T2 &lt;- Yt * (Time^2) df$T3 &lt;- Yt * (Time^3) df$T4 &lt;- Yt * (Time^4) detach(df) m.poly &lt;- lm(Yt ~ T1 + T2 + T3 + T4, data=df) summary(m.poly) Call: lm(formula = Yt ~ T1 + T2 + T3 + T4, data = df) Residuals: Min 1Q Median 3Q Max -0.0117491 -0.0046800 -0.0000683 0.0045719 0.0112732 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.113e-02 1.258e-03 16.80 &lt;2e-16 *** T1 6.366e-02 7.169e-04 88.80 &lt;2e-16 *** T2 -1.497e-03 3.100e-05 -48.28 &lt;2e-16 *** T3 1.510e-05 4.425e-07 34.12 &lt;2e-16 *** T4 -5.529e-08 2.055e-09 -26.90 &lt;2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.005506 on 95 degrees of freedom Multiple R-squared: 0.9998, Adjusted R-squared: 0.9998 F-statistic: 1.264e+05 on 4 and 95 DF, p-value: &lt; 2.2e-16 Then, predict and plot! Ypoly &lt;- predict(m.poly) plot(ts(Ypoly), col=&quot;blue1&quot;, lwd=2, ylab = (&quot;Ypoly (blue) | Ypred (red)&quot;)) lines(Ypred, col=&quot;red1&quot;, lwd=2) SPSS computes an \\(r^2\\) value for nonlinear regression models, which doesn’t make a lot of sense if you think about it. Here we van just compare the residual errors: Polynomial regression: \\(0.005506\\) Analytic solution: \\(0.002865\\)&quot; Slightly less residual error for the analytic solution, using less parameters to fit the model (3 vs. 5). More important:, the paramters of the analytic solution have a direct interpretation in terms of growth processes. "],
["hrvsol.html", "C.4 Heartbeat dynamics", " C.4 Heartbeat dynamics | jump to assignment | library(rio) TS1 &lt;- rio::import(&quot;https://github.com/FredHasselman/DCS/raw/master/assignmentData/RelativeRoughness/TS1.xlsx&quot;, col_names=FALSE) TS2 &lt;- rio::import(&quot;https://github.com/FredHasselman/DCS/raw/master/assignmentData/RelativeRoughness/TS2.xlsx&quot;, col_names=FALSE) TS3 &lt;- rio::import(&quot;https://github.com/FredHasselman/DCS/raw/master/assignmentData/RelativeRoughness/TS3.xlsx&quot;, col_names=FALSE) The Excel files did not have any column names, so let’s create them in the data.frame colnames(TS1) &lt;- &quot;TS1&quot; colnames(TS2) &lt;- &quot;TS2&quot; colnames(TS3) &lt;- &quot;TS3&quot; # Create a function for RR RR &lt;- function(ts){ # lag.max = n gives autocovariance of lags 0 ... n, VAR &lt;- acf(ts, lag.max = 1, type = &#39;covariance&#39;, plot=FALSE) # RR formula RelR &lt;- 2*(1-VAR$acf[2] / VAR$acf[1]) # Add some attributes to the output attributes(RelR) &lt;- list(localAutoCoVariance = VAR$acf[2], globalAutoCoVariance = VAR$acf[1]) return(RelR) } # Look at the results for(ts in list(TS1,TS2,TS3)){ relR &lt;- RR(ts[,1]) cat(paste0(colnames(ts),&quot;: RR = &quot;,round(relR,digits=3), &quot; = 2*(1-&quot;, round(attributes(relR)$localAutoCoVariance, digits = 4),&quot;/&quot;, round(attributes(relR)$globalAutoCoVariance,digits = 4),&quot;)\\n&quot;)) } TS1: RR = 0.485 = 2*(1-0.0016/0.0021) TS2: RR = 0.118 = 2*(1-0.0018/0.0019) TS3: RR = 2.052 = 2*(1--1e-04/0.002) Use Figure ?? to lookup which value of \\(RR\\) corresponds to which type of noise: TS1: Pink noise TS2: Brownian noise TS3: White noise C.4.1 Randomise To randomize the data you may use the function sample (which is easier than randperm) library(pracma) # randperm() TS1Random &lt;- TS1$TS1[randperm(length(TS1$TS1))] # sample() TS1Random &lt;- sample(TS1$TS1, length(TS1$TS1)) plot.ts(TS1Random) lines(ts(TS1$TS1),col=&quot;red3&quot;) If you repeat this for TS2 and TS3 and compute the Relative Roughness of each randomized time series, the outcomes should be around 2, white noise! This makes sense, you destroyed all the correlations in the data by removing the temporal order with which values were observed. C.4.2 Integrate Normalize the white noise time series TS3Norm &lt;- scale(TS3$TS3) Now integrate it, which just means, ‘take the cumulative sum’. TS3Int &lt;- cumsum(TS3Norm) plot.ts(TS3Int) lines(ts(TS3Norm),col=&quot;red3&quot;) If you compute the Relative Roughness of the integrated time series, the outcome should be close to 0, Brownian noise. RR(TS3Int) [1] 0.02783704 attr(,&quot;localAutoCoVariance&quot;) [1] 35.69734 attr(,&quot;globalAutoCoVariance&quot;) [1] 36.2012 -->"],
["fda1sol.html", "D Fluctuation and Disperion analyses I ", " D Fluctuation and Disperion analyses I "],
["psdsol.html", "D.1 Assignment: The Spectral Slope", " D.1 Assignment: The Spectral Slope | jump to assignment | First, load the data and source the function library. Example of using --ply functions Let’s try to use as few commands as possible to analyse all three timeseries. The easiest way to do this is to use the so-called apply family of functions. These functions pass the contents of a list object to a function. Suppose we need to calculate the means of column variables in 40 different SPSS .sav files stored in the folder DAT. With the rio package loaded we can execute the following commands: data &lt;- lapply(dir(&quot;/DAT/&quot;,pattern=&quot;.sav$&quot;),import) out &lt;- sapply(data,colMeans) The first command applies import to all files with a .sav extension found in the folder /DAT. It creates a dataframe for each file which are all stored as elements of the list object data. The second line applies the function colMeans to each element of data and puts the combined results in a matrix with the dataset ID as columns (1-40), dataset variables as rows and the calculated column means as cells. R comes with several apply functions installed, but an easier interface is provided by package plyr. When plyr is loaded you can use functions of the type XYply where X denotes the first letter of the input structure and Y the ouput structure: l for list, d for 'data.frame, a for array. So, laply() expects a listobject as input and will try to create an array as outout. There is also a special symbol for Y, the underscore _ if no output is expected, e.g. when plotting, l_ply. Data preparation Let’s prepare these series for spectral analysis. library(plyr) TSlist &lt;- list(TS1=TS1$TS1,TS2=TS2$TS2,TS3=TS3$TS3) # Plot raw l_ply(TSlist, plot.ts) # Normalise TSlist.n &lt;- llply(TSlist,scale) # Plot normalised l_ply(TSlist.n, plot.ts) # Detrend TSlist.nd &lt;- llply(TSlist.n, detrend) # Plot normalised, detrended l_ply(TSlist.nd, plot.ts) Time-series length Another preparation concerns checking wether the length of the series is a power of 2 (or 10). This is necessary for the Fourier transfrom to run smoothly. The code below uses log2 and nextpow2 to figure out whether the data length is ok. What is different from previous uses of the XYply functions is that we now customise the function we want to execute. The input is still a list object, each element of the list is passed as a variable ts to a so-called anonymous function, a function just denoted as function(ts). The function returns a data.frame with columns pow2, the current power of 2 and nextpow2 (a function of pracma) the next power of 2. The XYply functions will add an .id variable to the output if the input is a list with named fields. Although we create 3 data frames of one row, the d in ldply indicates these frames have to be merged if possible. ldply(TSlist.nd, function(ts) data.frame(pow2 = log2(length(ts)), nextpow2 = nextpow2(length(ts)))) .id pow2 nextpow2 1 TS1 11 11 2 TS2 11 11 3 TS3 11 11 In this case we don’t have to take any action, \\(2048\\) is a power of 2. Actions that could be taken are: removing datapoints from the front of the series, or, padding the series with zeroes. The fd.psd function The function created for spectral analysis fd.psd() will perform normalisation and detrending by default. It also returns information about the power spectrum and log-log fit. It’s good to know about the default settings of a function, and the return values. The best place to look for them is usually the help documentation, or the vignettes that come with a package. If you select a function in Rstudio and press F1 you’ll get the help page, If you press F2 can have a look at the code (if it is exported), or, you can call the function without parentheses fd.psd and the code will be printed to the Console. You can also hover the cursor after you typed the name of the function to reveal the arguments and defaults: Figure D.1: Get default values of function arguments. Another way to get this info is to use the function formals() formals(fd.psd) $y $fs NULL $normalize [1] TRUE $dtrend [1] TRUE $plot [1] FALSE Now we know this function has arguments normalize and dtrend set to TRUE, and plot set to FALSE. We could feed the fuction the raw data, or feed it our normalised, detrended, data and change the defaults. In the XYply functions, you can just add function arguments after the function name. # Analyse outPSD &lt;- llply(TSlist.nd, fd.psd, normalize = FALSE, dtrend = FALSE, plot=TRUE) fd.psd: Sample rate was set to 1. fd.psd: Sample rate was set to 1. fd.psd: Sample rate was set to 1. -->"],
["fda1so2.html", "E Fluctuation and Disperion analyses II", " E Fluctuation and Disperion analyses II There were no assignments for this Lecture. "],
["phase-space-reconstruction-and-recurrence-quantification-analysis-rqa.html", "F Phase Space Reconstruction and Recurrence Quantification Analysis (RQA)", " F Phase Space Reconstruction and Recurrence Quantification Analysis (RQA) First load some libraries . library(devtools) library(plyr) library(dplyr) library(fractal) library(plot3D) library(crqa) library(dygraphs) library(lattice) source_url(&quot;https://raw.githubusercontent.com/FredHasselman/DCS/master/functionLib/nlRtsa_SOURCE.R&quot;) "],
["PSRsol.html", "F.1 Phase Space Reconstruction of the Lorenz Attractor", " F.1 Phase Space Reconstruction of the Lorenz Attractor | Jump to assignment | Instead of rgl::plot3d we use plot3D::scatter3D to display the Lorenz attractor, because the 3D interactive plot doesn’t run inside this webbook. N &lt;- 3000 scatter3D(lorenz[1:N, 1], lorenz[1:N,2], lorenz[1:N,3], pch=&quot;.&quot;, col = &quot;black&quot;, colkey = FALSE, type = &quot;l&quot;) The three coupled equations of the Lorenz system constitute the three dimensions (X,Y and Z) of the state space of the system. lxyz &lt;- data.frame(t=1:N, lorenz[1:N, ]) dygraph(lxyz, main = &quot;Lorenz System - Chaotic Regime&quot;) %&gt;% dyHighlight(highlightCircleSize = 5, hideOnMouseOut = FALSE) %&gt;% dyOptions(colors = RColorBrewer::brewer.pal(3, &quot;Set2&quot;), drawGrid = FALSE) %&gt;% dyLegend(showZeroValues = TRUE) Embedding Lag Determine the embedding lag for optimal reconstruction. Use average mutual information as the criterion for selecting a delay. lagX &lt;- timeLag(lxyz$X, method = &quot;mutual&quot;, plot.data = TRUE) False Nearest Neighbours Determine how many points in the state space turn out to be neigbours if embedding dimension \\(n\\) is added to the state space \\(X(t), X(t + \\tau), \\ldots, X(t + n*\\tau)\\). (fnnX &lt;- FNN(lxyz$X, tlag = lagX)) False Nearest Neighbors for lxyz$X ---------------------------------- Series points : 3000 Embedding dimension(s) : 1 2 3 4 5 Time lag : 17 Oribital lag : 1 Neighbor tolerance (rtol) : 10 Attractor tolerance (atol) : 2 Test results (%): E=1 E=2 E=3 E=4 E=5 rtol 97.84 5.97 0 0 0 atol 1.42 0.00 0 0 0 combined 97.84 5.97 0 0 0 plotRP.fnn(fnnX) If you use plotRP.fnn(), the figure shows the combined result (grey circles), the maximum of two methods for determining whether points are false neighbours (atol and rtol). If you want to know the details, see the manual entry for FNN(). The combined method will give you the best value for embedding dimension in most contexts. Except… when you try to model a low dimensional system like the Predator-Prey system. Plot the reconstructed phase space Objects of the class embedSeries generated by embedSeries() have a special plot function: (lxxx &lt;- embedSeries(lxyz$X,dimension = 3, tlag = lagX)) Embedding matrix for lxyz$X --------------------------- Number of points : 2966 Embedding dimension(s) : 1 2 3 Time lag : 17 plot(lxxx, pch=&quot;.&quot;, col = &quot;black&quot;, type = &quot;l&quot;) Or use plot3D plot3D::scatter3D(lxxx[, 1], lxxx[,2], lxxx[,3], pch=&quot;.&quot;, col = &quot;black&quot;, colkey = FALSE, type = &quot;l&quot;) "],
["phase-space-reconstruction-of-the-predator-prey-system.html", "F.2 Phase Space Reconstruction of the Predator-Prey system", " F.2 Phase Space Reconstruction of the Predator-Prey system Get some iterations from the Predator-Prey system. # Parameters N &lt;- 2048 a &lt;- d &lt;- 1 b &lt;- c &lt;- 2 R0 &lt;- F0 &lt;- 0.1 R &lt;- as.numeric(c(R0, rep(NA,N-1))) F &lt;- as.numeric(c(F0, rep(NA,N-1))) # Time constant delta &lt;- 0.01 # Numerical integration of the logistic differential equation l_ply(seq_along(R), function(t){ R[[t+1]] &lt;&lt;- (a - b * F[t]) * R[t] * delta + R[t] F[[t+1]] &lt;&lt;- (c * R[t] - d) * F[t] * delta + F[t] }) Let’s plot the results. dygraph(data.frame(time=1:2049,Rabbits=R,Foxes=F), main = &quot;Predator-Prey System&quot;) %&gt;% dyHighlight(highlightCircleSize = 5, hideOnMouseOut = FALSE) %&gt;% dyOptions(colors = RColorBrewer::brewer.pal(3, &quot;Set2&quot;), drawGrid = FALSE) %&gt;% dyLegend(showZeroValues = TRUE) xyplot(R ~ F, pch = 16) Embedding Lag Determine the embedding lag for optimal reconstruction. Use average mutual information of Rabbits or Foxes as the criterion for selecting a delay. lagR &lt;- timeLag(R, method = &quot;mutual&quot;, plot.data = TRUE) False Nearest Neighbours Determine how many points in the state space turn out to be neigbours if embedding dimension \\(n\\) is added to the state space \\(R(t), R(t + \\tau), \\ldots, R(t + n*\\tau)\\). (fnnR &lt;- FNN(R, tlag = lagR)) False Nearest Neighbors for R ----------------------------- Series points : 2049 Embedding dimension(s) : 1 2 3 4 5 Time lag : 334 Oribital lag : 1 Neighbor tolerance (rtol) : 10 Attractor tolerance (atol) : 2 Test results (%): E=1 E=2 E=3 E=4 E=5 rtol 86.3 29.5 9.76 0 0 atol 10.0 0.0 0.00 0 0 combined 86.3 29.5 9.76 0 0 plotRP.fnn(fnnR) Plot the reconstructed phase space Objects of the class embedSeries generated by embedSeries() have a special plot function: (lRR &lt;- embedSeries(R,dimension = 2, tlag = lagR)) Embedding matrix for R ---------------------- Number of points : 1715 Embedding dimension(s) : 1 2 Time lag : 334 plot(lRR, pch=&quot;.&quot;, col = &quot;black&quot;, type = &quot;l&quot;) -->"],
["recurrence-quantification-analysis.html", "G Recurrence Quantification Analysis ", " G Recurrence Quantification Analysis "],
["RQAsol.html", "G.1 RQA of the Lorenz system", " G.1 RQA of the Lorenz system | Jump to assignment | Perform an RQA on the reconstructed state space of the Lorenz system. You’ll need a radius (also called: threshold) in order to decide which points are close together (recurrent). crqa provides a function which will automatically select the best parametersettings: optimizeParam() Best way to ensure you are using the same parameters in each function is to create some lists with parametersettings (check the crqa manual to figure out what these parameters mean): # General settings for `crqa()` par0 &lt;- list(rescale = 1, normalize = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, side = &quot;lower&quot;, checkl = list(do = FALSE, thrshd = 3, datatype = &quot;categorical&quot;,pad = TRUE) ) # Settings for `optimizeParam()` par &lt;- list(lgM = 20, steps = seq(1, 6, 1), radiusspan = 100, radiussample = 40, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, fnnpercent = 10, typeami = &quot;mindip&quot;) Get the optimal parameters using a radius which will give us 2%-5% recurrent points. (ans &lt;- optimizeParam(ts1 = lxyz$X, ts2 = lxyz$X, par = par, min.rec = 2, max.rec = 5)) $radius [1] 17.2439 $emddim [1] 2 $delay [1] 18 Run the RQA analysis using the same settings with which the parameters were found. crqaOutput &lt;- crqa(ts1 = lxyz$X, ts2 = lxyz$X, delay = ans$delay, embed = ans$emddim, radius = ans$radius, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, side = par0$side, checkl = par0$checkl ) The output of crqa is a list with recurrence measures, the last entry is the recurrence plot. It is represented as a so-called sparse-matrix. This representation severely decreases the amount of memory occupied by the recurrence matrix. It is basically a list of indices of cells that contain a \\(1\\). The \\(0\\) do not need to be stored. In order to plot this matrix you could use image(), but this does not produce the recurrence plot as they are usually displayed, the y-axis needs to be flipped. We created a function which will take as input the list output of crqa, together with lattice::levelplot the recurrence matrix can be created. If you have loaded (or sourced) the nlRtsa package you can call plotRP.crqa(crqaOutput). plotRP.crqa(crqaOutput) Loading required package: gridExtra Attaching package: &#39;gridExtra&#39; The following object is masked from &#39;package:dplyr&#39;: combine RP in crqa output is a Triangular Sparse Matrix, this implies auto-recurrence... Large RP with 8892324 elements... &gt;&gt; This could take some time to plot! "],
["rqa-of-the-circle-tracing-task.html", "G.2 RQA of the Circle Tracing Task", " G.2 RQA of the Circle Tracing Task Get the data generated during the lecture. library(rio) xy &lt;- import(&quot;https://raw.githubusercontent.com/FredHasselman/DCS/master/assignmentData/RQA_circletrace/mouse_circle_xy.csv&quot;) Embedding lag Determine the embedding lag. (lagXc &lt;- timeLag(xy$x, method = &quot;mutual&quot;, plot.data = TRUE)) [1] 86 attr(,&quot;data&quot;) [,1] [1,] 1.8748360 [2,] 1.8320247 [3,] 1.7597725 [4,] 1.6660259 [5,] 1.5695448 [6,] 1.4851768 [7,] 1.4155511 [8,] 1.3580141 [9,] 1.3099462 [10,] 1.2697228 [11,] 1.2346290 [12,] 1.2030061 [13,] 1.1738016 [14,] 1.1461442 [15,] 1.1202508 [16,] 1.0955800 [17,] 1.0723971 [18,] 1.0504011 [19,] 1.0295328 [20,] 1.0092911 [21,] 0.9901784 [22,] 0.9716143 [23,] 0.9539218 [24,] 0.9366875 [25,] 0.9201264 [26,] 0.9038439 [27,] 0.8881944 [28,] 0.8729000 [29,] 0.8582478 [30,] 0.8440019 [31,] 0.8302720 [32,] 0.8170165 [33,] 0.8042412 [34,] 0.7918786 [35,] 0.7798863 [36,] 0.7682832 [37,] 0.7568578 [38,] 0.7457565 [39,] 0.7349257 [40,] 0.7244155 [41,] 0.7141488 [42,] 0.7039729 [43,] 0.6938999 [44,] 0.6839407 [45,] 0.6741110 [46,] 0.6644834 [47,] 0.6549952 [48,] 0.6455323 [49,] 0.6361238 [50,] 0.6269657 [51,] 0.6179179 [52,] 0.6093046 [53,] 0.6010238 [54,] 0.5932492 [55,] 0.5856680 [56,] 0.5783174 [57,] 0.5710348 [58,] 0.5639222 [59,] 0.5569276 [60,] 0.5501662 [61,] 0.5434106 [62,] 0.5368340 [63,] 0.5304724 [64,] 0.5241171 [65,] 0.5178612 [66,] 0.5117279 [67,] 0.5056025 [68,] 0.4997365 [69,] 0.4941006 [70,] 0.4886011 [71,] 0.4832675 [72,] 0.4780774 [73,] 0.4732322 [74,] 0.4685945 [75,] 0.4640545 [76,] 0.4596915 [77,] 0.4553726 [78,] 0.4510386 [79,] 0.4469948 [80,] 0.4451781 [81,] 0.4438201 [82,] 0.4427879 [83,] 0.4411173 [84,] 0.4379825 [85,] 0.4335339 [86,] 0.4279071 [87,] 0.4235801 [88,] 0.4247762 [89,] 0.4280886 [90,] 0.4296760 [91,] 0.4286545 [92,] 0.4248078 [93,] 0.4197830 [94,] 0.4166983 [95,] 0.4162246 [96,] 0.4192973 [97,] 0.4245453 [98,] 0.4313695 [99,] 0.4381306 [100,] 0.4425022 [101,] 0.4452126 [102,] 0.4481473 [103,] 0.4521713 [104,] 0.4546178 [105,] 0.4562708 [106,] 0.4612016 [107,] 0.4687082 [108,] 0.4766385 [109,] 0.4846580 [110,] 0.4903264 [111,] 0.4931311 [112,] 0.4937906 [113,] 0.4931051 [114,] 0.4901800 [115,] 0.4862715 [116,] 0.4832530 [117,] 0.4829012 [118,] 0.4874575 [119,] 0.4968100 [120,] 0.5082572 [121,] 0.5202744 [122,] 0.5334663 [123,] 0.5470788 [124,] 0.5590956 [125,] 0.5690183 [126,] 0.5760787 [127,] 0.5810159 [128,] 0.5845512 [129,] 0.5854967 [130,] 0.5855992 [131,] 0.5874306 [132,] 0.5913599 [133,] 0.5955356 [134,] 0.5987059 [135,] 0.6024263 [136,] 0.6063072 [137,] 0.6093108 [138,] 0.6111368 [139,] 0.6118817 [140,] 0.6116046 [141,] 0.6124853 [142,] 0.6154613 [143,] 0.6188560 [144,] 0.6211657 [145,] 0.6219710 [146,] 0.6197909 [147,] 0.6144581 [148,] 0.6066394 [149,] 0.5968153 [150,] 0.5857086 [151,] 0.5734599 [152,] 0.5592622 [153,] 0.5423187 [154,] 0.5234938 [155,] 0.5033835 [156,] 0.4824005 [157,] 0.4633789 [158,] 0.4461670 [159,] 0.4296615 [160,] 0.4136314 [161,] 0.3978943 [162,] 0.3822670 [163,] 0.3669812 [164,] 0.3524403 [165,] 0.3386489 [166,] 0.3257262 [167,] 0.3149718 [168,] 0.3062398 [169,] 0.2990444 [170,] 0.2947886 [171,] 0.2939093 [172,] 0.2937713 [173,] 0.2929135 [174,] 0.2903755 [175,] 0.2865028 [176,] 0.2811382 [177,] 0.2744351 [178,] 0.2677695 [179,] 0.2617230 [180,] 0.2559572 [181,] 0.2506732 [182,] 0.2451949 [183,] 0.2392856 [184,] 0.2330739 [185,] 0.2262502 [186,] 0.2194679 [187,] 0.2136034 [188,] 0.2098218 [189,] 0.2079393 [190,] 0.2069279 [191,] 0.2062112 [192,] 0.2050514 [193,] 0.2027659 [194,] 0.1989667 [195,] 0.1940491 [196,] 0.1887533 [197,] 0.1837352 [198,] 0.1802085 [199,] 0.1787252 [200,] 0.1792536 [201,] 0.1802651 [202,] 0.1810710 attr(,&quot;lags&quot;) [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [18] 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 [35] 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 [52] 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 [69] 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 [86] 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 [103] 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 [120] 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 [137] 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 [154] 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 [171] 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 [188] 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 attr(,&quot;method&quot;) [1] &quot;mutual&quot; False Nearest Neighbours Run FNN to figure out the number of dimensions … we should get at least 2 (x and y, but maybe some other factors influenced the dynamics). In this case (as is the case with all real world data) we have to rescale the timeseries. A z-score transform (normalise) is usually ok, but sometimes a unit-scale transform (\\(0 \\cdots 1\\) may be necessary). (fnnXc &lt;- FNN(scale(xy$x), tlag = lagXc)) False Nearest Neighbors for scale(xy$x) --------------------------------------- Series points : 3500 Embedding dimension(s) : 1 2 3 4 5 Time lag : 86 Oribital lag : 1 Neighbor tolerance (rtol) : 10 Attractor tolerance (atol) : 2 Test results (%): E=1 E=2 E=3 E=4 E=5 rtol 99.3 37.42 4.77 0.381 0.0326 atol 19.1 0.55 0.00 0.000 0.0000 combined 99.3 37.42 4.77 0.381 0.0326 plotRP.fnn(fnnXc) We got a lag of 86 and an embedding dimension of \\(3\\) or \\(4\\). Three is actually not so strange, although we have recorded just 2 coordinates, there’s acceleration differences due to the biomechanics of the arm and hand, or resistance of the mouse on the surface, etc. Let’s see what package crqa tells us to choose automagically. We got a lag/delay of \\(86\\), let’s set the maximum lags to consider to \\(100\\) (lgM). # General settings for `crqa()` par0 &lt;- list(rescale = 1, normalize = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, side = &quot;lower&quot;, checkl = list(do = FALSE, thrshd = 3, pad = TRUE) ) # Settings for `optimizeParam()` par &lt;- list(lgM = 100, steps = seq(1, 6, 1), radiusspan = 100, radiussample = 40, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, fnnpercent = 10, typeami = &quot;mindip&quot;) (ansCircle &lt;- optimizeParam(ts1 = xy$x, ts2 = xy$x, par = par, min.rec = 2, max.rec = 5)) $radius [1] 17.96495 $emddim [1] 3 $delay [1] 94 The suggested embedding dimension is \\(3\\), the delay (lag) is somewhat higher, \\(94\\) than 86. These different values for the embedding lag shouldn’t influence the global pattern of the resuts. Run the RQA Run RQA with the optimal parameters. crqaOutput &lt;- crqa(ts1 = xy$x, ts2 = xy$x, delay = ansCircle$delay, embed = ansCircle$emddim, radius = ansCircle$radius, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, side = par0$side, checkl = par0$checkl ) plotRP.crqa(crqaOutput) RP in crqa output is a Triangular Sparse Matrix, this implies auto-recurrence... Large RP with 10969344 elements... &gt;&gt; This could take some time to plot! Run RQA with embedding lag 86 to check if the resulta will be very different. crqaOutput2 &lt;- crqa(ts1 = xy$x, ts2 = xy$x, delay = lagXc, embed = ansCircle$emddim, radius = ansCircle$radius, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, side = par0$side, checkl = par0$checkl ) plotRP.crqa(crqaOutput2) RP in crqa output is a Triangular Sparse Matrix, this implies auto-recurrence... Large RP with 11075584 elements... &gt;&gt; This could take some time to plot! {#RQA} Surrogate analysis Create constrained realisations of the data: random order - \\(H_0\\): the original data come from a process that generates random numbers. phase - \\(H_0\\): the original data come from a linear Gaussian process. AAFT - \\(H_0\\): the observed time series is a monotonic nonlinear transformation of a Gaussian process. rand.sur &lt;- xy$x[sample(length(xy$x))] phase.sur &lt;- surrogate(xy$x, method = &quot;phase&quot;) aaft.sur &lt;- surrogate(xy$x, method = &quot;aaft&quot;) Let’s plot the different realisations of the data. surplots &lt;- data.frame(X=c(xy$x,rand.sur,phase.sur,aaft.sur), t = rep(1:3500,4), type=factor(c(rep(&quot;Original&quot;,length(xy$x)), rep(&quot;Random order&quot;,length(rand.sur)), rep(&quot;Phase randomised&quot;,length(phase.sur)), rep(&quot;AAFT&quot;,length(aaft.sur)))) ) xyplot(X~t | type, data=surplots, type=&quot;l&quot;) crqaOutput.sur &lt;- llply(list(xy$x,rand.sur,phase.sur,aaft.sur), function(s){ crqa(ts1 = s, ts2 = s, delay = lagXc, embed = ansCircle$emddim, radius = ansCircle$radius, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, side = par0$side, checkl = par0$checkl ) }) l_ply(crqaOutput.sur,plotRP.crqa) RP in crqa output is a Triangular Sparse Matrix, this implies auto-recurrence... Large RP with 11075584 elements... &gt;&gt; This could take some time to plot! RP in crqa output is a Triangular Sparse Matrix, this implies auto-recurrence... Large RP with 11075584 elements... &gt;&gt; This could take some time to plot! RP in crqa output is a Triangular Sparse Matrix, this implies auto-recurrence... Large RP with 11075584 elements... &gt;&gt; This could take some time to plot! RP in crqa output is a Triangular Sparse Matrix, this implies auto-recurrence... Large RP with 11075584 elements... &gt;&gt; This could take some time to plot! A statistical test of the surrogate hypotheses The code below creates \\(99\\) RQA analyses based on AAFT surrogates. This takes a while, so we saved the reults, you can download the data from GitHub. crqaOutput.sur.aaft &lt;- llply(1:99, function(s){ xx &lt;- surrogate(xy$x, method = &quot;aaft&quot;) crqa(ts1 = xx, ts2 = xx, delay = lagXc, embed = ansCircle$emddim, radius = ansCircle$radius, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, side = par0$side, checkl = par0$checkl ) }) # Get the measures into a data.frame df &lt;- ldply(1:99, function(s) data.frame(crqaOutput.sur.aaft[[s]][1:9])) # Add the original df[100,] &lt;- data.frame(crqaOutput2[1:9]) export(df,&quot;crqaOutput_aaft.csv&quot;) Now lets compare the original RQA measures to to the surrogate measures by rank order. df &lt;- import(&quot;https://raw.githubusercontent.com/FredHasselman/DCS/master/assignmentData/RQA_circletrace/crqaOutput_aaft.csv&quot;) dotplot(1:100~sort(DET), data=df) # Our observed determinism was the largest value (max(df$DET)==crqaOutput2$DET) [1] FALSE For Determinism, the nullhypothesis that the observed time series is a monotonic nonlinear transformation of a Gaussian process, can be rejected at \\(p &lt;.01\\). Here’s a summary of all measures, not all of them have the highest rank: rbind.data.frame(maxSurrogate=colwise(max)(df[1:99,]), original= df[100,]) RR DET NRLINE maxL L ENTR rENTR maxSurrogate 1.118225 97.99402 14635 3327 10.21021 3.071098 0.6815321 original 1.831344 99.35415 5295 3327 38.05892 4.338005 0.7897244 LAM TT maxSurrogate 98.82649 10.35873 original 99.91767 15.89280 -->"],
["categorical-and-cross-rqa-crqa.html", "H Categorical and Cross-RQA (CRQA)", " H Categorical and Cross-RQA (CRQA) If you haven’t done so already, look at the solutions to the auto-RQA assignments "],
["CRQAsol.html", "H.1 Assignment: Cross Recurrence Quantification Analysis", " H.1 Assignment: Cross Recurrence Quantification Analysis | Jump to assignment | Create two variables for CRQA analysis: y1 &lt;- sin(1:900*2*pi/67) y2 &lt;- sin(.01*(1:900*2*pi/67)^2) You have just created two sine waves. We’ll examine if and how they are coupled in a shared phase space. As a first step plot them. Find an embedding delay (using mutual information) and an embedding dimension (if you calculate an embedding dimension using package fractal for each signal seperately, as a rule of thumb use the highest embedding dimension you find in further analyses). # General settings for `crqa()` par0 &lt;- list(rescale = 0, normalize = 0, mindiagline = 2, minvertline = 2, tw = 0, whiteline = FALSE, recpt = FALSE, side = &quot;both&quot;, checkl = list(do = FALSE, thrshd = 3, datatype = &quot;categorical&quot;,pad = TRUE) ) # Settings for `optimizeParam()` par &lt;- list(lgM = 20, steps = seq(1, 6, 1), radiusspan = 100, radiussample = 40, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, fnnpercent = 10, typeami = &quot;mindip&quot;) We can now create a cross recurrence matrix. Fill in the values you decided on. You can choose a radius automatically, look in the crqa manual. Note: There is no rescaling of data, the sines were created in the same range. You can plot a matrix using image(). You could also check package nonlinearTseries. If you sourced the nlRtsa library, use plotRP.crqa() Get the optimal parameters using a radius which will give us 2%-5% recurrent points. (ans &lt;- optimizeParam(ts1 = y1, ts2 = y2, par = par, min.rec = 2, max.rec = 5)) $radius [1] 0.2128611 $emddim [1] 2 $delay [1] 15 Run the CRQA. crqaOutput &lt;- crqa(ts1 = y1, ts2 = y2, delay = ans$delay, embed = ans$emddim, radius = ans$radius, normalize = par0$normalize, rescale = par0$rescale, mindiagline = par0$mindiagline, minvertline = par0$minvertline, tw = par0$tw, whiteline = par0$whiteline, recpt = par0$recpt, side = par0$side, checkl = par0$checkl ) Can you understand what is going on? Explain the the lack of recurrent points at the beginning of the time series. plotRP.crqa(crqaOutput) Examine the synchronisation under the diagonal LOS. Look in the manual of crqa or Coco &amp; Dale (2014). Make a plot of the diagonal profie. How far is the peak in RR removes from 0 (Line of Synchronisation)? This is based on the timeseries (without embedding) win &lt;- 50 (res &lt;- drpdfromts(y1, y2, ws = win, datatype = &#39;continuous&#39;, radius = ans$radius))[2:3] $maxrec [1] 0.3080357 $maxlag [1] 55 plot(-win:win,res$profile,type = &quot;l&quot;, lwd = 5, xlab = &quot;Delays&quot;, ylab = &quot;Recurrence&quot;) abline(v=0) To get the diagonal profile from the recurrence plot, use spdiags(). dprofile &lt;- spdiags(crqaOutput$RP) plot(-win:win,colMeans(dprofile$B[, between(dprofile$d, -win,win)]), type=&quot;l&quot;, lwd = 5, xlab = &quot;Delays&quot;, ylab = &quot;Recurrence&quot;) abline(v=0) Perform the same steps with a shuffled version (or use surrogate analysis!) of the data of timeseries \\(y1\\). You can use the embedding parameters you found earlier. "],
["catCRQAsol.html", "H.2 Assignment: Categorical CRQA", " H.2 Assignment: Categorical CRQA The solutions are basically in the paper by Coco &amp; Dale, the purpose here is to introduce the parametersettings used for CRQA. | Jump to assignment | -->"],
["cuspsol.html", "I The Cusp Catasrophe Model &amp; Warning Signs", " I The Cusp Catasrophe Model &amp; Warning Signs "],
["netssol.html", "J Complex Networks", " J Complex Networks To complete these assignments you need: library(igraph) Attaching package: &#39;igraph&#39; The following object is masked from &#39;package:dygraphs&#39;: %&gt;% The following objects are masked from &#39;package:dplyr&#39;: %&gt;%, as_data_frame, groups, union The following objects are masked from &#39;package:stats&#39;: decompose, spectrum The following object is masked from &#39;package:base&#39;: union library(qgraph) "],
["basic-graphs.html", "J.1 Basic graphs", " J.1 Basic graphs # Create a small graph and plot it g &lt;- graph.ring(20) plot(g) # Get the degree of each node degree(g) [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 # Get the average path length average.path.length(g) [1] 5.263158 # Create a &quot;Small world&quot; graph g &lt;- watts.strogatz.game(1, 20, 5, 0.05) # Get the degree of each node degree(g) [1] 7 10 10 12 10 11 10 11 10 12 10 10 11 10 10 9 8 11 11 7 # Get the average path length average.path.length(g) [1] 1.473684 # Get the transitivity transitivity(g) [1] 0.5915033 plot(g) # Directed &quot;scale free&quot; graph set.seed(456) g &lt;- barabasi.game(20) plot(g) # Get the degree of each node degree(g) [1] 7 4 2 4 1 2 1 3 1 2 1 1 2 1 1 1 1 1 1 1 # Get the average path length average.path.length(g) [1] 1.571429 # Get the transitivity transitivity(g) [1] 0 To check for a power-law, remember what the scaling relation is supposed to represent: A relation between number of nodes of a particular size, with the size of those nodes. The following produces an unsorted graph: plot(log(1:20),log(degree(g))) So, we need to sort: plot(log(1:20),sort(log(degree(g)), decreasing = TRUE)) Or even better, sort and bin it: d &lt;- degree(g) y &lt;- hist(d,breaks=0.5:(max(d)+0.5),plot=TRUE, xlab = &quot;Node degree&quot;)$counts op &lt;-par(&quot;xlog&quot;,&quot;ylog&quot;) plot(1:length(y),rev(y), xlim = c(length(y),1), xlab = &quot;Node degree (log)&quot;, ylab = &quot;Frequency of Node degree (log)&quot;, log= c(&quot;xy&quot;)) Warning in xy.coords(x, y, xlabel, ylabel, log): 2 y values &lt;= 0 omitted from logarithmic plot par(op) (alpha=coef(lm(rev(log1p(y)) ~ log1p(1:length(y))))) (Intercept) log1p(1:length(y)) -0.992961 1.283407 "],
["social-networks.html", "J.2 Social Networks", " J.2 Social Networks Social network of friendships between 34 members of a karate club at a US university in the 1970s. See W. W. Zachary, An information flow model for conflict and fission in small groups, Journal of Anthropological Research 33, 452-473 (1977). # Community membership karate &lt;- graph.famous(&quot;Zachary&quot;) wc &lt;- walktrap.community(karate) plot(wc, karate) modularity(wc) [1] 0.3532216 membership(wc) [1] 1 1 2 1 5 5 5 1 2 2 5 1 1 2 3 3 5 1 3 1 3 1 3 4 4 4 3 4 2 3 2 2 3 3 # What does this matrix look like? get.adjacency(karate) 34 x 34 sparse Matrix of class &quot;dgCMatrix&quot; [1,] . 1 1 1 1 1 1 1 1 . 1 1 1 1 . . . 1 . 1 . 1 . . . . . . . . . 1 . . [2,] 1 . 1 1 . . . 1 . . . . . 1 . . . 1 . 1 . 1 . . . . . . . . 1 . . . [3,] 1 1 . 1 . . . 1 1 1 . . . 1 . . . . . . . . . . . . . 1 1 . . . 1 . [4,] 1 1 1 . . . . 1 . . . . 1 1 . . . . . . . . . . . . . . . . . . . . [5,] 1 . . . . . 1 . . . 1 . . . . . . . . . . . . . . . . . . . . . . . [6,] 1 . . . . . 1 . . . 1 . . . . . 1 . . . . . . . . . . . . . . . . . [7,] 1 . . . 1 1 . . . . . . . . . . 1 . . . . . . . . . . . . . . . . . [8,] 1 1 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . [9,] 1 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 1 [10,] . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 [11,] 1 . . . 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . [12,] 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . [13,] 1 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . [14,] 1 1 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 [15,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 [16,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 [17,] . . . . . 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . [18,] 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . [19,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 [20,] 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 [21,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 [22,] 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . [23,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 [24,] . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . 1 . . 1 1 [25,] . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 . . . 1 . . [26,] . . . . . . . . . . . . . . . . . . . . . . . 1 1 . . . . . . 1 . . [27,] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . . . 1 [28,] . . 1 . . . . . . . . . . . . . . . . . . . . 1 1 . . . . . . . . 1 [29,] . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 1 [30,] . . . . . . . . . . . . . . . . . . . . . . . 1 . . 1 . . . . . 1 1 [31,] . 1 . . . . . . 1 . . . . . . . . . . . . . . . . . . . . . . . 1 1 [32,] 1 . . . . . . . . . . . . . . . . . . . . . . . 1 1 . . 1 . . . 1 1 [33,] . . 1 . . . . . 1 . . . . . 1 1 . . 1 . 1 . 1 1 . . . . . 1 1 1 . 1 [34,] . . . . . . . . 1 1 . . . 1 1 1 . . 1 1 1 . 1 1 . . 1 1 1 1 1 1 1 . 34 people sre in the karate class, a 1 is printed if they know each other. You can do a clustering analysis for any 0-1 matrix! "],
["small-world-index-and-degree-distribution.html", "J.3 Small World Index and Degree Distribution", " J.3 Small World Index and Degree Distribution Select and run all the code below This will compute the Small World Index and compute the Power Law slope Fit of Small world networks and Scale-free networks Compare the measures! # Initialize set.seed(660) layout1=layout.kamada.kawai k=3 n=50 # Setup plots par(mfrow=c(2,3)) # Strogatz rewiring probability = .00001 p &lt;- 0.00001 p1 &lt;- plotSW(n=n,k=k,p=p) PLF1&lt;- PLFsmall(p1) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used Warning in PLFsmall(p1): Less than 2 points in Log-Log regression... alpha=0 p11 &lt;- plot(p1,main=&quot;p = 0.00001&quot;,layout=layout1,xlab=paste(&quot;FON = &quot;,round(mean(neighborhood.size(p1,order=1)),digits=1),&quot;\\nSWI = &quot;, round(SWtestE(p1,N=100)$valuesAV$SWI,digits=2),&quot;\\nPLF = NA&quot;,sep=&quot;&quot;)) # Strogatz rewiring probability = .01 p &lt;- 0.01 p2 &lt;- plotSW(n=n,k=k,p=p) PLF2&lt;- PLFsmall(p2) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used p22 &lt;- plot(p2,main=&quot;p = 0.01&quot;,layout=layout1,xlab=paste(&quot;FON = &quot;,round(mean(neighborhood.size(p2,order=1)),digits=1),&quot;\\nSWI = &quot;, round(SWtestE(p2,N=100)$valuesAV$SWI,digits=2),&quot;\\nPLF = &quot;,round(PLF2,digits=2),sep=&quot;&quot;)) # Strogatz rewiring probability = 1 p &lt;- 1 p3 &lt;- plotSW(n=n,k=k,p=p) PLF3&lt;- PLFsmall(p3) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used p33 &lt;- plot(p3,main=&quot;p = 1&quot;,layout=layout1,xlab=paste(&quot;FON = &quot;,round(mean(neighborhood.size(p3,order=1)),digits=1),&quot;\\nSWI = &quot;, round(SWtestE(p3,N=100)$valuesAV$SWI,digits=2),&quot;\\nPLF = &quot;,round(PLF3,digits=2),sep=&quot;&quot;)) set.seed(200) # Barabasi power = 0 p4 &lt;- plotBA(n=n,pwr=0,out.dist=hist(degree(p1,mode=&quot;all&quot;),breaks=(0:n),plot=F)$density) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used PLF4&lt;- PLFsmall(p4) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used p44 &lt;- plot(p4,main=&quot;power = 0&quot;,layout=layout1,xlab=paste(&quot;FON = &quot;,round(mean(neighborhood.size(p4,order=1)),digits=1),&quot;\\nSWI = &quot;, round(SWtestE(p4,N=100)$valuesAV$SWI,digits=2),&quot;\\nPLF = &quot;,round(PLF4,digits=2),sep=&quot;&quot;)) # Barabasi power = 2 p5 &lt;- plotBA(n=n,pwr=2,out.dist=hist(degree(p2,mode=&quot;all&quot;),breaks=(0:n),plot=F)$density) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used PLF5&lt;- PLFsmall(p5) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used p55 &lt;- plot(p5,main=&quot;power = 2&quot;,layout=layout1,xlab=paste(&quot;FON = &quot;,round(mean(neighborhood.size(p5,order=1)),digits=1),&quot;\\nSWI = &quot;, round(SWtestE(p5,N=100)$valuesAV$SWI,digits=2),&quot;\\nPLF = &quot;,round(PLF5,digits=2),sep=&quot;&quot;)) # Barabasi power = 4 p6 &lt;- plotBA(n=n,pwr=4,out.dist=hist(degree(p3,mode=&quot;all&quot;),breaks=(0:n),plot=F)$density) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used PLF6&lt;- PLFsmall(p6) Warning in if (plot) {: the condition has length &gt; 1 and only the first element will be used p66 &lt;- plot(p6,main=&quot;power = 4&quot;,layout=layout1,xlab=paste(&quot;FON = &quot;,round(mean(neighborhood.size(p6,order=1)),digits=1),&quot;\\nSWI = &quot;, round(SWtestE(p6,N=100)$valuesAV$SWI,digits=2),&quot;\\nPLF = &quot;,round(PLF6,digits=2),sep=&quot;&quot;)) par(mfrow=c(1,1)) The PLF fit is unreliable, there are not enough nodes and different values for degree. the SWI does seem to follow the small-wordledness / scale-free topology quite closely. -->"]
]
